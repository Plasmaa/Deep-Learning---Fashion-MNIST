# -*- coding: utf-8 -*-
"""5.Fashion_MNIST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WoADppeDStlomTGsg5LshzD7WAb6beV3
"""

import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns

(train_images, train_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# Reduce dataset size for faster training
N_train = 5000
N_test = 1000
train_images = train_images[:N_train]
train_labels = train_labels[:N_train]
test_images = test_images[:N_test]
test_labels = test_labels[:N_test]

print(f"Train images shape: {train_images.shape}")
print(f"Train labels shape: {train_labels.shape}")
print(f"Test images shape: {test_images.shape}")
print(f"Test labels shape: {test_labels.shape}")
print(f"Number of classes: {len(np.unique(train_labels))}")

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
plt.suptitle("Sample Fashion MNIST Images", y=1.02, fontsize=16)
plt.show()

print("\nTrain Label Distribution:")
unique_train_labels, counts_train_labels = np.unique(train_labels, return_counts=True)
for label, count in zip(unique_train_labels, counts_train_labels):
    print(f"{class_names[label]}: {count} samples")

print("\nTest Label Distribution:")
unique_test_labels, counts_test_labels = np.unique(test_labels, return_counts=True)
for label, count in zip(unique_test_labels, counts_test_labels):
    print(f"{class_names[label]}: {count} samples")

# Check pixel value range
print(f"\nMin pixel value: {train_images.min()}")
print(f"Max pixel value: {train_images.max()}")

train_images_cnn = train_images / 255.0
test_images_cnn = test_images / 255.0

# Reshape images to add a channel dimension (28, 28, 1) for CNN input
train_images_cnn = train_images_cnn.reshape((train_images_cnn.shape[0], 28, 28, 1))
test_images_cnn = test_images_cnn.reshape((test_images_cnn.shape[0], 28, 28, 1))

print(f"\nTrain images shape for CNN: {train_images_cnn.shape}")
print(f"Test images shape for CNN: {test_images_cnn.shape}")

train_images_flat = train_images.reshape(train_images.shape[0], -1) / 255.0
test_images_flat = test_images.reshape(test_images.shape[0], -1) / 255.0

scaler = StandardScaler()
train_images_scaled = scaler.fit_transform(train_images_flat)
test_images_scaled = scaler.transform(test_images_flat)

print(f"Train images shape for Traditional ML (flattened): {train_images_flat.shape}")
print(f"Test images shape for Traditional ML (flattened): {test_images_flat.shape}")
print(f"Train images shape for Traditional ML (scaled): {train_images_scaled.shape}")
print(f"Test images shape for Traditional ML (scaled): {test_images_scaled.shape}")

print("\n--- Training Logistic Regression ---")
log_reg_model = LogisticRegression(solver='saga', multi_class='multinomial', max_iter=200, n_jobs=-1, verbose=0)
log_reg_model.fit(train_images_scaled, train_labels)
print("Logistic Regression training complete.")

print("\n--- Training Random Forest Classifier ---")
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, verbose=0)
rf_model.fit(train_images_scaled, train_labels)
print("Random Forest Classifier training complete.")

# --- Model 3: Support Vector Machine (SVC) ---
print("\n--- Training Support Vector Machine (SVC) ---")
svm_model = SVC(kernel='rbf', random_state=42, verbose=False)
svm_model.fit(train_images_scaled, train_labels)
print("SVC training complete (full dataset).")

print("\n--- Building and Training CNN ---")
# Define the CNN model architecture
cnn_model = keras.Sequential([
    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    keras.layers.MaxPooling2D((2, 2)),
    keras.layers.Conv2D(64, (3, 3), activation='relu'),
    keras.layers.MaxPooling2D((2, 2)),
    keras.layers.Conv2D(64, (3, 3), activation='relu'),
    keras.layers.Flatten(),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dropout(0.5),  # Regularization to prevent overfitting
    keras.layers.Dense(10, activation='softmax')  # 10 classes, softmax for probability distribution
])

cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
cnn_model.summary()

history = cnn_model.fit(train_images_cnn, train_labels, epochs=10, validation_split=0.2, verbose=1)
print("CNN training complete.")

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

print("\n--- Evaluating Traditional Machine Learning Models ---")
models = {
    "Logistic Regression": log_reg_model,
    "Random Forest": rf_model,
    "SVC": svm_model
}
results = {}

for name, model in models.items():
    print(f"\n--- {name} ---")
    predictions = model.predict(test_images_scaled)
    accuracy = accuracy_score(test_labels, predictions)
    report = classification_report(test_labels, predictions, target_names=class_names, zero_division=0)
    cm = confusion_matrix(test_labels, predictions)
    results[name] = {
        "accuracy": accuracy,
        "report": report,
        "confusion_matrix": cm
    }
    print(f"Accuracy: {accuracy:.4f}")
    print("Classification Report:\n", report)

    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.title(f'{name} Confusion Matrix')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

print("\n--- Evaluating Convolutional Neural Network (CNN) ---")
loss, accuracy = cnn_model.evaluate(test_images_cnn, test_labels, verbose=0)
print(f"CNN Test Loss: {loss:.4f}")
print(f"CNN Test Accuracy: {accuracy:.4f}")

# Get predictions and classification report for CNN
cnn_pred_probs = cnn_model.predict(test_images_cnn)
cnn_predictions = np.argmax(cnn_pred_probs, axis=1)
cnn_report = classification_report(test_labels, cnn_predictions, target_names=class_names, zero_division=0)
cnn_cm = confusion_matrix(test_labels, cnn_predictions)

results["CNN"] = {
    "accuracy": accuracy,
    "report": cnn_report,
    "confusion_matrix": cnn_cm
}

print("CNN Classification Report:\n", cnn_report)

plt.figure(figsize=(8, 6))
sns.heatmap(cnn_cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.title('CNN Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

print("\n--- Summary of Model Performance (Test Accuracy) ---")
for name, data in results.items():
    print(f"{name}: {data['accuracy']:.4f}")

# --- Making Predictions with Different Models ---
# Select a few random test images to make predictions on
num_predictions_to_show = 5
random_indices = np.random.choice(len(test_images), num_predictions_to_show, replace=False)

print("\n--- Making Predictions on Sample Test Images ---")
for i, idx in enumerate(random_indices):
    sample_image = test_images[idx]
    true_label = test_labels[idx]
    true_label_name = class_names[true_label]

    print(f"\n--- Sample {i+1} (True Label: {true_label_name}) ---")

    # Display the actual image
    plt.figure(figsize=(2,2))
    plt.imshow(sample_image, cmap=plt.cm.binary)
    plt.title(f"True: {true_label_name}")
    plt.xticks([])
    plt.yticks([])
    plt.show()

    # Prediction with Logistic Regression
    lr_pred_input = test_images_scaled[idx].reshape(1, -1)
    lr_prediction = log_reg_model.predict(lr_pred_input)[0]
    print(f"Logistic Regression Prediction: {class_names[lr_prediction]}")

for i, idx in enumerate(random_indices):
  # Prediction with Logistic Regression
    lr_pred_input = test_images_scaled[idx].reshape(1, -1)
    lr_prediction = log_reg_model.predict(lr_pred_input)[0]
    print(f"Logistic Regression Prediction: {class_names[lr_prediction]}")

    # Prediction with Random Forest
    rf_pred_input = test_images_scaled[idx].reshape(1, -1)
    rf_prediction = rf_model.predict(rf_pred_input)[0]
    print(f"Random Forest Prediction: {class_names[rf_prediction]}")

     # Prediction with SVC
    svm_pred_input = test_images_scaled[idx].reshape(1, -1)
    svm_prediction = svm_model.predict(svm_pred_input)[0]
    print(f"SVC Prediction: {class_names[svm_prediction]}")

    # Prediction with CNN
    cnn_pred_input = test_images_cnn[idx].reshape(1, 28, 28, 1)  # Reshape for CNN
    cnn_pred_probs = cnn_model.predict(cnn_pred_input)[0]
    cnn_prediction = np.argmax(cnn_pred_probs)
    print(f"CNN Prediction: {class_names[cnn_prediction]} (Confidence: {np.max(cnn_pred_probs)*100:.2f}%)")
    print(f"CNN Top 3 Probabilities: ")
    top_3_indices = np.argsort(cnn_pred_probs)[::-1][:3]
    for k in top_3_indices:
        print(f" - {class_names[k]}: {cnn_pred_probs[k]*100:.2f}%")

print("\n--- Decision Making based on Model Performance ---")
print("Choosing the 'best' model depends on your specific needs:")

best_model_name = max(results, key=lambda k: results[k]['accuracy'])
print(f"\nBased purely on test accuracy, the best model is: {best_model_name} (Accuracy: {results[best_model_name]['accuracy']:.4f})")

if best_model_name == "CNN":
    print("The CNN achieved the highest accuracy, which is typical for image classification.")
    print("Decision: If maximum accuracy is the primary goal, and computational resources (for training and inference) are not a constraint, the CNN is likely the best choice.")
    print("Considerations: CNNs require more computational power and data for training. They are typically less interpretable than traditional models.")
elif best_model_name in ["Logistic Regression", "Random Forest", "SVC"]:
    print(f"A traditional ML model ({best_model_name}) achieved the highest or comparable accuracy.")
    print("Decision: If interpretability, faster training times, or lower computational demands are crucial, a traditional model might be preferred, especially if its performance is close to or even surpasses deep learning for your specific dataset.")
    print("Considerations: Random Forests are good for feature importance. Logistic Regression is simple and interpretable. SVC can be powerful but slower on large datasets.")

print("\nFurther Considerations for Decision Making:")
print("- **Computational Resources:** Training and deploying complex CNNs can be expensive.")
print("- **Inference Speed:** Real-time applications might prefer faster, simpler models if accuracy difference is negligible.")
print("- **Interpretability:** Why did the model make a specific prediction? Traditional models often provide more transparency.")
print("- **Data Size:** Deep learning models typically require vast amounts of data to reach their full potential.")
print("- **Deployment Environment:** What kind of hardware is available for running the model in production?")

# testing data --

# Select new test data for prediction
num_test_samples = 10
test_indices = np.random.choice(len(test_images), num_test_samples, replace=False)

# Create the output table
print("| # | New Data | Prediction | Decision |")
print("|---|---|---|---|---|")
print("| 1 | Sample Image 1 | Predicted Class: | Decision explanation |")
print("|   | [Description of sample] | Probability distribution | |")

for i, idx in enumerate(test_indices, 1):
    sample_image = test_images[idx]
    true_label = test_labels[idx]
    true_label_name = class_names[true_label]

    # Get predictions from all models
    # CNN prediction
    cnn_pred_input = test_images_cnn[idx].reshape(1, 28, 28, 1)
    cnn_pred_probs = cnn_model.predict(cnn_pred_input, verbose=0)[0]
    cnn_prediction = np.argmax(cnn_pred_probs)
    cnn_confidence = np.max(cnn_pred_probs)

    # Traditional model predictions (using Random Forest as example)
    rf_pred_input = test_images_scaled[idx].reshape(1, -1)
    rf_prediction = rf_model.predict(rf_pred_input)[0]
    rf_probs = rf_model.predict_proba(rf_pred_input)[0]

    # Display the sample image
    plt.figure(figsize=(2,2))
    plt.imshow(sample_image, cmap=plt.cm.binary)
    plt.title(f"Sample {i}: True: {true_label_name}")
    plt.xticks([])
    plt.yticks([])
    plt.show()

    # Print prediction results in table format
    print(f"| {i} | Sample Image {i} (True: {true_label_name}) | Predicted Class: {class_names[cnn_prediction]} | ")
    print(f"|   | Image features: {sample_image.shape} | Confidence: {cnn_confidence:.4f} | Model: CNN |")

    # Add decision explanation
    if cnn_prediction == true_label:
        decision = "Correct prediction. The model accurately classified this fashion item."
    else:
        decision = f"Incorrect prediction. Model confused {class_names[cnn_prediction]} with {true_label_name}."

    print(f"|   | | Top 3 probabilities: | {decision} |")

    # Show top 3 predictions
    top_3_indices = np.argsort(cnn_pred_probs)[::-1][:3]
    for j, class_idx in enumerate(top_3_indices, 1):
        prob = cnn_pred_probs[class_idx]
        print(f"|   | | {j}. {class_names[class_idx]}: {prob:.4f} | |")